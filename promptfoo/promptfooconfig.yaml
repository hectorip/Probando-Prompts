# This configuration compares LLM output of 2 prompts x 2 GPT models across 3 test cases.
# Learn more: https://promptfoo.dev/docs/configuration/guide
description: 'Evaluando con promptfoo'

prompts:
  - "Dame ideas para hacer mi proyecto final de arquitectura de software de la industria {{industria}}"
  - "Describe 5 proyectos que puedan servir para mi proyecto del curso de arquitectura de software, tienen que ser muy pequeños  y fáciles de programar porque me tengo que enfocar en la parte de la estrategia, dame el resultado en JSON y enfócate en la industria {{industria}}"


providers:
  - openai:chat:gpt-3.5-turbo
  - openai:chat:gpt-4o

tests:
  - vars:
      topic: financiera

  - vars:
      topic: de servicios para startups
    assert:
      # For more information on assertions, see https://promptfoo.dev/docs/configuration/expected-outputs
      - type: icontains
        value: startups 
      - type: javascript
        value: 1 / (output.length + 1)  # prefer shorter outputs

  - vars:
      topic: hoteles
    assert:
      # For more information on model-graded evals, see https://promptfoo.dev/docs/configuration/expected-outputs/model-graded
      - type: llm-rubric
        value: asegúrata de que los proyectos son sencillos