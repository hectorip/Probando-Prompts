# Learn more about building a configuration: https://promptfoo.dev/docs/configuration/guide
description: 'My eval'

prompts:
  - "Fulfill this user helpdesk ticket: {{inquiry}}"
  

providers:
  - "openai:gpt-3.5-turbo"
  - "openai:gpt-4o"
  

tests:
  - vars:
      inquiry: "I have a problem with my order"
      context: file://context.py

  - vars:
      inquiry: "I want to return my widget"
      # See how to use dynamic context to e.g. use a vector store https://promptfoo.dev/docs/guides/evaluate-rag/#using-dynamic-context
      context: file://context.py
    assert:
      # For more information on assertions, see https://promptfoo.dev/docs/configuration/expected-outputs

      # Make sure output contains the phrase "return label"
      - type: icontains
        value: "return label"

      # Prefer shorter outputs
      - type: python
        value: 1 / (len(output) + 1)

  - vars:
      inquiry: "I need help with my account"
      context: |
        You can also hardcode context directly in the configuration.
        Username: Foobar
        Account ID: 123456
    assert:
      # For more information on model-graded evals, see https://promptfoo.dev/docs/configuration/expected-outputs/model-graded
      - type: llm-rubric
        value: ensure that the output is friendly and empathetic
